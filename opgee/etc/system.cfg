[DEFAULT]

# This project is used if '-P' flag not given to the 'gt' command
OPGEE.DefaultProject =

# This defines the variable for documentation purposes. The value
# is set automatically in each project section to the name of that
# section -- unless a non-blank value already exists in the section.
OPGEE.ProjectName =

# Root directory for where the user keeps project folders
OPGEE.ProjectRoot = %(Home)s/projects
OPGEE.ProjectDir  = %(OPGEE.ProjectRoot)s/%(OPGEE.ProjectName)s

# Where to find plug-ins. Internal plugin directory is added
# automatically. Use this to add custom plug-ins outside the opgee
# source tree. The value is a semicolon-delimited (on Windows) or
# colon-delimited (on Unix) string of directories to search for files
# matching the pattern '*_plugin.py'
OPGEE.PluginPath = %(OPGEE.ProjectDir)s/plugins

# Where to find user-defined LCA model classes. The value is one or more
# Python files or directories, delimited by semicolon (on Windows) or colon
# (on Unix). For directories, all '.py' files found in the directory are
# loaded.
OPGEE.ClassPath =

# Ordinarily, an error is raised if encounter a redefinition of a Process
# subclass. To allow the option of overriding built-in subclasses, the user
# can set this flag to True, which merely emits a warning rather than raising
# an exception.
OPGEE.AllowProcessRedefinition = False

# Where to find user's customizations
OPGEE.UserXmlDirectory = %(Home)s/opgee/%(OPGEE.ProjectName)s

# Default model file, if this variable is not defined, is the built-in opgee.xml
OPGEE.ModelFile =

# Where to find user's attributes.xml files (optional)
OPGEE.UserAttributesFile =

# Allow user to provide comma-delimited list of additional components
# that should be allowed in Streams.
OPGEE.StreamComponents =

# If set to a filename, the final expanded, merged XML is save there
OPGEE.XmlSavePathname =

# Change this if desired to increase or decrease diagnostic messages.
# A default value can be set here, and a project-specific value can
# be set in the project's config file section.
# Possible values (from most to least verbose) are:
# DEBUG, INFO, WARNING, ERROR, CRITICAL
OPGEE.LogLevel = INFO

OPGEE.LogConsole = True

# If set, application logger messages are written here.
OPGEE.LogDir = %(Home)s/tmp
OPGEE.LogFile = %(OPGEE.LogDir)s/opgee.log

# Format strings for log files and console messages. Note doubled
# '%%' required here around logging parameters to avoid attempted
# variable substitution within the config system.
OPGEE.LogFileFormat    = %%(asctime)s %%(levelname)s %%(name)s:%%(lineno)d %%(message)s
OPGEE.LogConsoleFormat = %%(levelname)s %%(name)s: %%(message)s

# Where to create temporary files
OPGEE.TempDir = /tmp

# For debugging purposes: tool.py can show a stack trace on error
OPGEE.ShowStackTrace = False

# TextEditor to open via the --edit option to the 'config' sub-command
OPGEE.TextEditor = vi

# This is the two subprocesses excluded to calculate energy consumption for the NG reinjection option
# energy for all other subprocesses is summarized and converted to the amount of NG consumed
OPGEE.ExcludeFromReinjectionEnergySummary = GasReinjectionCompressor, GasReinjectionWell

OPGEE.FunctionalUnits = oil, gas
OPGEE.Boundaries      = Production, Transportation, Distribution

# 0 implies use os.cpu_count()
OPGEE.CPUsToUse = 0

# Default value for runsim --mode argument. Can be: local, cluster
OPGEE.RunsimMode = local

# Assume no slurm unless user sets this to "True"
SLURM.Available = False

# Where to chdir to before running sbatch script
SLURM.RunDir = %(Home)s/slurm

SLURM.MinutesPerTask = 10

SLURM.HeadMemPerCPU = 100m
SLURM.WorkerMemPerCPU = 100m

# The default partition (other options on Sherlock are: normal, owners)
SLURM.Partition = normal

# Default assumes use of anaconda, but user can redefine SLURM.LoadEnvironment
# to change this
SLURM.CondaEnvironment = opgee

# A command to run on compute nodes to set up required environment
SLURM.LoadEnvironment = conda activate %(SLURM.CondaEnvironment)s

# The name to give the job when running on SLURM
SLURM.JobName = opgee-mcs

# The partition (queue) to submit the job to on SLURM
SLURM.Partition = normal

# Location of log file for use on SLURM
SLURM.LogFile = %(OPGEE.LogDir)s/opgee-slurm.log

# The Ray "head" involves several processes. For the head, we allocate an
# entire node and assume cpu_count - 8 of the CPUs are available for workers.
# These process appear to by running when "ray start --head ..." is executed:
#  1. ray start --head
#  2. gcs_server
#  3. python monitor.py
#  4. python ray.util.client.server
#  5. python dashboard.py
#  6. raylet
#  7. python log_monitor.py
#  8. python agent.py
Ray.HeadProcs = 8

# File for coordinating between Ray head and workers
Ray.AddressFile = %(Home)s/.ray-cluster-address

# Something other than 6379, which can conflict with redis
Ray.Port = 6888

# Where to put ray log file session directories
Ray.TempDir = %($GROUP_SCRATCH)s/opgee
